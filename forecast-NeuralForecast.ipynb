{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, NHITS,LSTM, NHITS, RNN\n",
    "from sklearn.preprocessing import Normalizer,QuantileTransformer,StandardScaler,MinMaxScaler\n",
    "# Disable logging messages unless there is an error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def plot_df(df):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Check if the DataFrame 'dfs' is empty\n",
    "    if df.empty:\n",
    "        print(\"Error: DataFrame is empty.\")\n",
    "        # Handle the error as desired, e.g., raise an exception or return an error message\n",
    "\n",
    "    # Plot the data\n",
    "    ax.plot(df[\"ds\"], df[\"y\"])\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.set_title(\"Data Plot\")\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"history_processed.csv\", parse_dates=[\"ds\"])\n",
    "df['unique_id'] = '1D'\n",
    "df = df[df['ds']>='2018-01-01']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df = df[df.ds<='2023-12-31'] \n",
    "Y_test_df = df[df.ds>'2023-12-31'] \n",
    "# Fit and predict with NBEATS and NHITS models\n",
    "horizon = len(Y_test_df)\n",
    "models = [NBEATS(input_size=2 * horizon, h=horizon, max_steps=100),\n",
    "          NHITS(input_size=2 * horizon, h=horizon, max_steps=100),\n",
    "          LSTM(h=horizon,                    # Forecast horizon\n",
    "               max_steps=500,                # Number of steps to train\n",
    "               scaler_type='standard',       # Type of scaler to normalize data\n",
    "               encoder_hidden_size=64,       # Defines the size of the hidden state of the LSTM\n",
    "               decoder_hidden_size=64,),     # Defines the number of hidden units of each layer of the MLP decoder\n",
    "          NHITS(h=horizon,                   # Forecast horizon\n",
    "                input_size=2 * horizon,      # Length of input sequence\n",
    "                max_steps=100,               # Number of steps to train\n",
    "                n_freq_downsample=[2, 1, 1])]\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='D')\n",
    "nf.fit(df=Y_train_df)\n",
    "Y_hat_df = nf.predict().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "# Plot predictions\n",
    "fig, ax = plt.subplots(1, 1, figsize = (20, 7)) # Create a figure and axes object\n",
    "\n",
    "Y_hat_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds']) # Merge predicted and actual values by unique_id and ds\n",
    "\n",
    "plot_df = pd.concat([Y_train_df, Y_hat_df]).set_index('ds') # Concatenate training and predicted values by 'ds' index\n",
    "\n",
    "plot_df[['y', 'NBEATS', 'NHITS', 'LSTM', 'NHITS']].plot(ax=ax, linewidth=2) # Plot actual and predicted values with different colors and linewidth\n",
    "\n",
    "ax.set_title('USD Forecast', fontsize=22) # Set the title of the plot\n",
    "ax.set_ylabel('Daily Price', fontsize=20) # Set the y-axis label\n",
    "ax.set_xlabel('Timestamp [t]', fontsize=20) # Set the x-axis label\n",
    "ax.legend(prop={'size': 15}) # Create a legend for the plot\n",
    "ax.grid() # Add a grid to the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time = len(df.ds.unique())\n",
    "val_size = int(.2 * n_time)\n",
    "test_size = int(.2 * n_time)\n",
    "print(f\"{n_time},{val_size},{test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tramsformer models supported by NeuralForecast:\n",
    "# Infomer, Autoformer, FEDformer and Patchfomer\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import Informer, Autoformer, FEDformer, PatchTST\n",
    "horizon = 96 # 24hrs = 4 * 15 min.\n",
    "models = [Informer(h=horizon,                 # Forecasting horizon\n",
    "                input_size=horizon,           # Input size\n",
    "                max_steps=1000,               # Number of training iterations\n",
    "                val_check_steps=100,          # Compute validation loss every 100 steps\n",
    "                early_stop_patience_steps=3), # Stop training if validation loss does not improve\n",
    "          Autoformer(h=horizon,\n",
    "                input_size=horizon,\n",
    "                max_steps=1000,\n",
    "                val_check_steps=100,\n",
    "                early_stop_patience_steps=3),\n",
    "          PatchTST(h=horizon,\n",
    "                input_size=horizon,\n",
    "                max_steps=1000,\n",
    "                val_check_steps=100,\n",
    "                early_stop_patience_steps=3),\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NeuralForecast(\n",
    "    models=models,\n",
    "    freq='D')\n",
    "\n",
    "Y_hat_df = nf.cross_validation(df=df,\n",
    "                               val_size=val_size,\n",
    "                               test_size=test_size,\n",
    "                               n_windows=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_plot = Y_hat_df[Y_hat_df['unique_id']=='OT'] # OT dataset\n",
    "cutoffs = Y_hat_df['cutoff'].unique()[::horizon]\n",
    "Y_plot = Y_plot[Y_hat_df['cutoff'].isin(cutoffs)]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(Y_plot['ds'], Y_plot['y'], label='True')\n",
    "plt.plot(Y_plot['ds'], Y_plot['Informer'], label='Informer')\n",
    "plt.plot(Y_plot['ds'], Y_plot['Autoformer'], label='Autoformer')\n",
    "plt.plot(Y_plot['ds'], Y_plot['PatchTST'], label='PatchTST')\n",
    "plt.xlabel('Datestamp')\n",
    "plt.ylabel('OT')\n",
    "plt.grid()\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.losses.numpy import mae\n",
    "mae_informer = mae(Y_hat_df['y'], Y_hat_df['Informer'])\n",
    "mae_autoformer = mae(Y_hat_df['y'], Y_hat_df['Autoformer'])\n",
    "mae_patchtst = mae(Y_hat_df['y'], Y_hat_df['PatchTST'])\n",
    "\n",
    "print(f'Informer: {mae_informer:.3f}')\n",
    "print(f'Autoformer: {mae_autoformer:.3f}')\n",
    "print(f'PatchTST: {mae_patchtst:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@misc{olivares2022library_neuralforecast,\n",
    "    author={Kin G. Olivares and\n",
    "            Cristian Chall√∫ and\n",
    "            Federico Garza and\n",
    "            Max Mergenthaler Canseco and\n",
    "            Artur Dubrawski},\n",
    "    title = {{NeuralForecast}: User friendly state-of-the-art neural forecasting models.},\n",
    "    year={2022},\n",
    "    howpublished={{PyCon} Salt Lake City, Utah, US 2022},\n",
    "    url={https://github.com/Nixtla/neuralforecast}\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcst-NeuralProphet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
