{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer,QuantileTransformer,StandardScaler,MinMaxScaler\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "# Disable logging messages unless there is an error\n",
    "set_log_level(\"ERROR\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "url = 'https://dashboard-api.tgju.org/v1/tv/history?symbol=PRICE_DOLLAR_RL&resolution=1D&from=1681492565&to=1712678305'\n",
    "try:\n",
    "    res = requests.get(url=url)\n",
    "    res_j = res.json()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error occurred during request: {e}\")\n",
    "\n",
    "# Get the column names from the dictionary\n",
    "column_names = list(res_j.keys())\n",
    "\n",
    "res_j.pop('s')\n",
    "res_j.pop('v')\n",
    "\n",
    "# Create the DataFrame\n",
    "try:\n",
    "  df = pd.DataFrame.from_dict(res_j)\n",
    "except pd.errors.ParserError as e:\n",
    "  print(f\"Error occurred while parsing the data: {e}\")\n",
    "\n",
    "# Convert the unix timestamp column to datetime\n",
    "try:\n",
    "  df['t'] = pd.to_datetime(df['t'],unit='s')\n",
    "except pd.errors.OutOfBoundsDatetime as e:\n",
    "  print(f\"Error occurred while converting the timestamp: {e}\")\n",
    "\n",
    "df.to_csv('df.csv', index=False)\n",
    "# Select the relevant columns\n",
    "dfs = df[['t','c']].copy()\n",
    "# Rename the columns\n",
    "dfs.rename(columns={'t':'ds','c':'y'}, inplace= True)\n",
    "# Filter the data to start from 2017-01-01\n",
    "dfs = dfs[dfs['ds'] >= '2017-01-01'].reset_index().drop(columns='index')\n",
    "# Drop duplicates\n",
    "dfs = dfs.drop_duplicates(subset=['ds'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dfs[\"y\"] = scaler.fit_transform(dfs[\"y\"].values.reshape(-1, 1))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "dfs.to_csv('df.csv', index=False)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Check if the DataFrame 'dfs' is empty\n",
    "if dfs.empty:\n",
    "    print(\"Error: DataFrame is empty.\")\n",
    "    # Handle the error as desired, e.g., raise an exception or return an error message\n",
    "\n",
    "# # Normalise the 'y' column\n",
    "# dfs[\"y2\"] = (dfs[\"y\"] - dfs[\"y\"].min()) / (dfs[\"y\"].max() - dfs[\"y\"].min())\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# dfs[\"y3\"] = scaler.fit_transform(dfs[\"y\"].values.reshape(-1, 1))\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# dfs[\"y4\"] = scaler.fit_transform(dfs[\"y\"].values.reshape(-1, 1))\n",
    "\n",
    "# transformer = QuantileTransformer(n_quantiles=10)\n",
    "# dfs[\"y5\"] = transformer.fit_transform(dfs[\"y\"].values.reshape(-1, 1))\n",
    "\n",
    "# normalizer = Normalizer(norm=\"l2\")\n",
    "# dfs[\"y6\"] = normalizer.fit_transform(dfs[\"y\"].values.reshape(-1, 1))\n",
    "# Plot the data\n",
    "ax.plot(dfs[\"ds\"], dfs[\"y\"])\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax.set_title(\"Data Plot\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NeuralProphet model\n",
    "m = NeuralProphet(\n",
    "    weekly_seasonality=6,  # Set weekly seasonality to 6 days\n",
    "    learning_rate=0.01,  # Set learning rate to 0.01\n",
    ")\n",
    "m.set_plotting_backend(\"plotly-static\")  # show plots correctly in jupyter notebooks\n",
    "m = m.add_country_holidays(\"IR\")\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df_train, df_test = m.split_df(dfs, freq=\"D\", valid_p=1.0 / 12)\n",
    "\n",
    "# Fit the model to the training data\n",
    "metrics = m.fit(df_train, freq=\"D\", validation_df=df_test, progress=\"plot\")\n",
    "\n",
    "\n",
    "# Print the model metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a forecast object using the model\n",
    "forecast = m.predict(df_train)\n",
    "\n",
    "# Set the plotting backend to \"plotly-static\"\n",
    "m.set_plotting_backend(\"plotly-static\")\n",
    "\n",
    "# Plot the forecast using the set plotting backend\n",
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(df_test)\n",
    "m = m.highlight_nth_step_ahead_of_each_forecast(1)\n",
    "m.plot(forecast[-7 * 24 :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python function to test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
